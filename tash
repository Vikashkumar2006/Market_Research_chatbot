[1mdiff --git a/README.md b/README.md[m
[1mindex 9e6c0c1..2c031c7 100644[m
[1m--- a/README.md[m
[1m+++ b/README.md[m
[36m@@ -73,22 +73,111 @@[m [mThis chatbot uses NVIDIA's AI services through their API. The backend:[m
 3. Returns the AI-generated responses to the frontend[m
 4. Presents the information in a user-friendly format[m
 [m
[32m+[m[32m## ðŸ§ Step-by-Step: Integrating an API Key to Make a Chatbot[m
[32m+[m
[32m+[m[32m### ðŸ›  1. Choose Your Stack (Frontend/Backend)[m
[32m+[m[32mLetâ€™s keep it simple:[m
[32m+[m
[32m+[m[32m- **Frontend:** React / HTML + JS[m
[32m+[m[32m- **Backend:** Node.js / Python (Flask or FastAPI are great)[m
[32m+[m[32m- **API:** OpenAI, or another chatbot service[m
[32m+[m
[32m+[m[32m### ðŸ” 2. Get Your API Key[m
[32m+[m[32m- Sign up at https://platform.openai.com/[m
[32m+[m[32m- Go to your **API keys** under user settings[m
[32m+[m[32m- Click **Create new secret key**, then copy it (and **never** hardcode it into frontend JSâ€”unless you want it stolen like candy from a baby ðŸ‘¶ðŸ­)[m
[32m+[m
[32m+[m[32m### ðŸ“¦ 3. Set Up Environment Variables (Safe Storage)[m
[32m+[m[32mIn your **backend**, create a `.env` file:[m
[32m+[m
[32m+[m[32m```env[m
[32m+[m[32mOPENAI_API_KEY=sk-your-key-here[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32mThen load it in your code (e.g., using `dotenv` in Node.js):[m
[32m+[m
[32m+[m[32m```js[m
[32m+[m[32mrequire('dotenv').config();[m
[32m+[m[32mconst apiKey = process.env.OPENAI_API_KEY;[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32mOr in Python:[m
[32m+[m
[32m+[m[32m```python[m
[32m+[m[32mfrom dotenv import load_dotenv[m
[32m+[m[32mimport os[m
[32m+[m[32mload_dotenv()[m
[32m+[m[32mapi_key = os.getenv("OPENAI_API_KEY")[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### ðŸ”„ 4. Create a Backend Endpoint to Call the API[m
[32m+[m
[32m+[m[32m**Example (Node.js + Express):**[m
[32m+[m
[32m+[m[32m```js[m
[32m+[m[32mconst express = require('express');[m
[32m+[m[32mconst axios = require('axios');[m
[32m+[m[32mrequire('dotenv').config();[m
[32m+[m
[32m+[m[32mconst app = express();[m
[32m+[m[32mapp.use(express.json());[m
[32m+[m
[32m+[m[32mapp.post('/chat', async (req, res) => {[m
[32m+[m[32m  const userMessage = req.body.message;[m
[32m+[m
[32m+[m[32m  try {[m
[32m+[m[32m    const response = await axios.post('https://api.openai.com/v1/chat/completions', {[m
[32m+[m[32m      model: "gpt-3.5-turbo",[m
[32m+[m[32m      messages: [{ role: "user", content: userMessage }][m
[32m+[m[32m    }, {[m
[32m+[m[32m      headers: {[m
[32m+[m[32m        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,[m
[32m+[m[32m        'Content-Type': 'application/json'[m
[32m+[m[32m      }[m
[32m+[m[32m    });[m
[32m+[m
[32m+[m[32m    res.json(response.data.choices[0].message);[m
[32m+[m[32m  } catch (err) {[m
[32m+[m[32m    res.status(500).send("Something went wrong: " + err.message);[m
[32m+[m[32m  }[m
[32m+[m[32m});[m
[32m+[m
[32m+[m[32mapp.listen(3000, () => console.log('Server running on http://localhost:3000'));[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### ðŸ§¼ 5. Frontend Calls Backend[m
[32m+[m
[32m+[m[32m```js[m
[32m+[m[32mconst sendMessage = async (message) => {[m
[32m+[m[32m  const res = await fetch("http://localhost:3000/chat", {[m
[32m+[m[32m    method: "POST",[m
[32m+[m[32m    headers: { "Content-Type": "application/json" },[m
[32m+[m[32m    body: JSON.stringify({ message })[m
[32m+[m[32m  });[m
[32m+[m
[32m+[m[32m  const data = await res.json();[m
[32m+[m[32m  console.log("Bot says:", data.content);[m
[32m+[m[32m};[m
[32m+[m[32m```[m
[32m+[m
[32m+[m[32m### ðŸ” Bonus: Hide Your Key in Production[m
[32m+[m[32m- NEVER expose your key in frontend JS[m
[32m+[m[32m- Use a proxy server/backend[m
[32m+[m[32m- For deployment, store your `.env` values in services like Vercel, Render, or Heroku environment settings[m
[32m+[m
 ## Troubleshooting Deployment[m
 [m
 If you encounter errors during deployment, try these solutions:[m
 [m
 ### Error: Cannot find package.json[m
[31m-[m
 - Make sure your package.json is in the repository root (not in a subdirectory)[m
 - Verify the rootDir setting in render.yaml points to where package.json is located[m
 [m
 ### Error: Cannot find module 'express' or 'openai'[m
[31m-[m
 - Check if dependencies are properly installed by running `npm install` locally[m
 - Verify the build command is correctly set to `npm install`[m
 [m
 ### Error: API key related issues[m
[31m-[m
 - Ensure the NVIDIA_API_KEY environment variable is set correctly in Render[m
 - Check the API key permissions and quotas in your NVIDIA account[m
 [m
[36m@@ -121,4 +210,5 @@[m [mMIT[m
 [m
 ## Author[m
 [m
[31m-Your Name[m
[32m+[m[32mAmandeep Singh[m
[41m+[m
[1mdiff --git a/package-lock.json b/package-lock.json[m
[1mindex 575edf8..2c12ae5 100644[m
[1m--- a/package-lock.json[m
[1m+++ b/package-lock.json[m
[36m@@ -9,9 +9,8 @@[m
       "version": "1.0.0",[m
       "license": "MIT",[m
       "dependencies": {[m
[31m-        "dotenv": "^16.3.1",[m
         "express": "^4.18.2",[m
[31m-        "openai": "^4.28.0"[m
[32m+[m[32m        "openai": "^4.91.1"[m
       },[m
       "devDependencies": {[m
         "nodemon": "^3.0.1"[m
[36m@@ -325,18 +324,6 @@[m
         "npm": "1.2.8000 || >= 1.4.16"[m
       }[m
     },[m
[31m-    "node_modules/dotenv": {[m
[31m-      "version": "16.4.7",[m
[31m-      "resolved": "https://registry.npmjs.org/dotenv/-/dotenv-16.4.7.tgz",[m
[31m-      "integrity": "sha512-47qPchRCykZC03FhkYAhrvwU4xDBFIj1QPqaarj6mdM/hgUzfPHcpkHJOn3mJAufFeeAxAzeGsr5X0M4k6fLZQ==",[m
[31m-      "license": "BSD-2-Clause",[m
[31m-      "engines": {[m
[31m-        "node": ">=12"[m
[31m-      },[m
[31m-      "funding": {[m
[31m-        "url": "https://dotenvx.com"[m
[31m-      }[m
[31m-    },[m
     "node_modules/dunder-proto": {[m
       "version": "1.0.1",[m
       "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",[m
[1mdiff --git a/package.json b/package.json[m
[1mindex d8261bc..e240e4e 100644[m
[1m--- a/package.json[m
[1m+++ b/package.json[m
[36m@@ -17,7 +17,6 @@[m
   "author": "",[m
   "license": "MIT",[m
   "dependencies": {[m
[31m-    "dotenv": "^16.3.1",[m
     "express": "^4.18.2",[m
     "openai": "^4.28.0"[m
   },[m
[1mdiff --git a/server.js b/server.js[m
[1mindex dbc9cd2..49e10ea 100644[m
[1m--- a/server.js[m
[1m+++ b/server.js[m
[36m@@ -1,7 +1,6 @@[m
 const express = require("express");[m
 const path = require("path");[m
 const { OpenAI } = require("openai");[m
[31m-require("dotenv").config();[m
 const app = express();[m
 [m
 // Set the port based on environment variable or default to 3000[m
[36m@@ -9,7 +8,9 @@[m [mconst PORT = process.env.PORT || 3000;[m
 [m
 // Initialize OpenAI with NVIDIA API[m
 const openai = new OpenAI({[m
[31m-  apiKey: process.env.NVIDIA_API_KEY,[m
[32m+[m[32m  apiKey:[m
[32m+[m[32m    process.env.NVIDIA_API_KEY ||[m
[32m+[m[32m    "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",[m
   baseURL: "https://integrate.api.nvidia.com/v1",[m
 });[m
 [m
